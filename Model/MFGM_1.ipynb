{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3yl7S-gKwCF1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"L1zkMjUgAegY"},"source":["### GPU info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GN0XPaF2AjzK"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"eGynxt4w_yNB"},"source":["### 切換路徑"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFXiA5d01lx6"},"outputs":[],"source":["cd MFGM"]},{"cell_type":"markdown","metadata":{"id":"dPAbmQ4DANlg"},"source":["## 模型架構"]},{"cell_type":"markdown","metadata":{"id":"pxZpG_QUANlg"},"source":["### Lib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42iXEetaANlg"},"outputs":[],"source":["\n","# Util #\n","import pickle\n","import numpy as np\n","import os\n","import scipy.sparse as sp\n","import torch\n","from scipy.sparse import linalg\n","from torch.autograd import Variable\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Layer #\n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","from torch.nn import init\n","import numbers\n","import torch.nn.functional as F\n","\n","# Model #\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import sys\n","\n","# Trainer #\n","import torch.optim as optim\n","import math\n","\n","# Main #\n","import torch\n","import numpy as np\n","import argparse\n","import time\n","import matplotlib.pyplot as plt\n","\n","\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"markdown","metadata":{"id":"9m9BJMEvANlh"},"source":["### Util"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v3lArIYWANlh"},"outputs":[],"source":["\n","class DataLoaderM(object):\n","    def __init__(self, xs, ys, xs_1, xs_2, batch_size, pad_with_last_sample=True):\n","        \"\"\"\n","        :param xs:\n","        :param ys:\n","        :param batch_size:\n","        :param pad_with_last_sample: pad with the last sample to make number of samples divisible to batch_size.\n","        \"\"\"\n","        self.batch_size = batch_size\n","        self.current_ind = 0\n","\n","        # 將資料長度補齊至batch_size可整除之數量\n","        # 補齊方法: 取原資料最後一個並複製多個來補齊\n","        if pad_with_last_sample:\n","            # 計算需補齊數量\n","            num_padding = (batch_size - (len(xs) % batch_size)) % batch_size\n","            x_padding = np.repeat(xs[-1:], num_padding, axis=0)\n","            y_padding = np.repeat(ys[-1:], num_padding, axis=0)\n","\n","            # 將複製後的ele進行concatenate以補齊成可整除batch_size之長度\n","            xs = np.concatenate([xs, x_padding], axis=0)\n","            ys = np.concatenate([ys, y_padding], axis=0)\n","\n","            xs_1 = np.concatenate([xs_1, x_padding], axis=0)\n","            xs_2 = np.concatenate([xs_2, x_padding], axis=0)\n","\n","        self.size = len(xs)\n","        self.num_batch = int(self.size // self.batch_size)\n","        self.xs = xs\n","        self.ys = ys\n","\n","        self.xs_1 = xs_1\n","        self.xs_2 = xs_2\n","\n","    def shuffle(self):\n","        permutation = np.random.permutation(self.size)\n","        xs, ys = self.xs[permutation], self.ys[permutation]\n","        self.xs_1 = self.xs_1[permutation]\n","        self.xs_2 = self.xs_2[permutation]\n","\n","        self.xs = xs\n","        self.ys = ys\n","\n","    def get_iterator(self):\n","        self.current_ind = 0\n","        def _wrapper():\n","            while self.current_ind < self.num_batch:\n","                start_ind = self.batch_size * self.current_ind\n","                end_ind = min(self.size, self.batch_size * (self.current_ind + 1))\n","                x_i = self.xs[start_ind: end_ind, ...]\n","                y_i = self.ys[start_ind: end_ind, ...]\n","\n","                x_i_1 = self.xs_1[start_ind: end_ind, ...]\n","                x_i_2 = self.xs_2[start_ind: end_ind, ...]\n","\n","                # 節省記憶體:\n","                # yield 設計來的目的，就是為了單次輸出內容\n","                # 我們可以把 yield 暫時看成 return，但是這個 return 的功能只有單次\n","                # 而且，一旦我們的程式執行到 yield 後，程式就會把值丟出，並暫時停止\n","                yield (x_i, y_i, x_i_1, x_i_2)\n","                self.current_ind += 1\n","\n","        return _wrapper()\n","\n","class StandardScaler():\n","    \"\"\"\n","    Standard the input\n","    \"\"\"\n","    def __init__(self, mean, std):\n","        self.mean = mean\n","        self.std = std\n","    def transform(self, data):\n","        return (data - self.mean) / self.std\n","    def inverse_transform(self, data):\n","        return (data * self.std) + self.mean\n","'''\n","\n","class StandardScaler():\n","    \"\"\"\n","    Standard the input\n","    \"\"\"\n","    def __init__(self, max, min):\n","        self.max = max\n","        self.min = min\n","    def transform(self, data):\n","        return (data - self.min) / (self.max - self.min)\n","    def inverse_transform(self, data):\n","        return (data * (self.max - self.min) ) + self.min\n","'''\n","\n","def asym_adj(adj):\n","    \"\"\"Asymmetrically normalize adjacency matrix.\"\"\"\n","    adj = sp.coo_matrix(adj)\n","    rowsum = np.array(adj.sum(1)).flatten()\n","    d_inv = np.power(rowsum, -1).flatten()\n","    d_inv[np.isinf(d_inv)] = 0.\n","    d_mat= sp.diags(d_inv)\n","    return d_mat.dot(adj).astype(np.float32).todense()\n","\n","\n","def load_pickle(pickle_file):\n","    try:\n","        with open(pickle_file, 'rb') as f:\n","            pickle_data = pickle.load(f)\n","    except UnicodeDecodeError as e:\n","        with open(pickle_file, 'rb') as f:\n","            pickle_data = pickle.load(f, encoding='latin1')\n","    except Exception as e:\n","        print('Unable to load data ', pickle_file, ':', e)\n","        raise\n","    return pickle_data\n","\n","def load_adj(pkl_filename, adjtype):\n","    sensor_ids, sensor_id_to_ind, adj_mx = load_pickle(pkl_filename)\n","\n","    print('# 全部L.A.的sensor ID(sensor_ids):\\n',sensor_ids)\n","    print('# 將sensor ID對應index(sensor_id_to_ind):\\n',sensor_id_to_ind)\n","\n","    if adjtype == \"scalap\":\n","        adj = [calculate_scaled_laplacian(adj_mx)]\n","    elif adjtype == \"normlap\":\n","        adj = [calculate_normalized_laplacian(adj_mx).astype(np.float32).todense()]\n","    elif adjtype == \"symnadj\":\n","        adj = [sym_adj(adj_mx)]\n","    elif adjtype == \"transition\":\n","        adj = [asym_adj(adj_mx)]\n","    elif adjtype == \"doubletransition\":\n","        adj = [asym_adj(adj_mx), asym_adj(np.transpose(adj_mx))]   # asym_adj(adj_mx): forward transition matrix / asym_adj(np.transpose(adj_mx)): backward transition matrix\n","    elif adjtype == \"identity\":\n","        adj = [np.diag(np.ones(adj_mx.shape[0])).astype(np.float32)]\n","    else:\n","        error = 0\n","        assert error, \"adj type not defined\"\n","\n","    print('# Double transition Transition matrix of Eq 4:\\n',adj)\n","    return sensor_ids, sensor_id_to_ind, adj\n","\n","def load_dataset(dataset_dir, batch_size, valid_batch_size= None, test_batch_size=None):\n","    data = {}\n","    for category in ['train', 'val', 'test']:\n","        cat_data = np.load(os.path.join(dataset_dir, category + '.npz'))\n","        data['x_' + category] = cat_data['x']\n","        data['y_' + category] = cat_data['y']\n","\n","        if args.log_print:\n","            print(\"# category:\", category)\n","            print('x:',data['x_' + category].shape, data['x_' + category][0] )\n","            print('y:',data['y_' + category].shape, data['y_' + category][0] )\n","\n","    # 使用train的mean/std來正規化valid/test #\n","    scaler = StandardScaler(mean=data['x_train'][..., 0].mean(), std=data['x_train'][..., 0].std())\n","    # 將欲訓練特徵改成正規化\n","    for category in ['train', 'val', 'test']:\n","        data['x_' + category][..., 0] = scaler.transform(data['x_' + category][..., 0])\n","\n","\n","\n","    data['train_loader'] = DataLoaderM(data['x_train'], data['y_train'], batch_size)\n","    data['val_loader'] = DataLoaderM(data['x_val'], data['y_val'], valid_batch_size)\n","    data['test_loader'] = DataLoaderM(data['x_test'], data['y_test'], test_batch_size)\n","    data['scaler'] = scaler\n","    return data\n","\n","\n","\n","def masked_mse(preds, labels, null_val=np.nan):\n","    if np.isnan(null_val):\n","        mask = ~torch.isnan(labels)\n","    else:\n","        mask = (labels!=null_val)\n","    mask = mask.float()\n","    mask /= torch.mean((mask))\n","    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n","    loss = (preds-labels)**2\n","    loss = loss * mask\n","    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n","    return torch.mean(loss)\n","\n","def masked_rmse(preds, labels, null_val=np.nan):\n","    return torch.sqrt(masked_mse(preds=preds, labels=labels, null_val=null_val))\n","\n","\n","def masked_mae(preds, labels, null_val=np.nan):\n","    if np.isnan(null_val):\n","        mask = ~torch.isnan(labels)\n","    else:\n","        mask = (labels!=null_val)\n","    mask = mask.float()\n","    mask /=  torch.mean((mask))\n","    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n","    loss = torch.abs(preds-labels)\n","    loss = loss * mask\n","    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n","    return torch.mean(loss)\n","def masked_mape(preds, labels, null_val=np.nan):\n","    if np.isnan(null_val):\n","        mask = ~torch.isnan(labels)\n","    else:\n","        mask = (labels!=null_val)\n","    mask = mask.float()\n","    mask /=  torch.mean((mask))\n","    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n","    loss = torch.abs(preds-labels)/labels\n","    #loss = 2.0 * torch.mean(torch.abs(preds - labels) / (torch.abs(preds) + torch.abs(labels)))\n","    loss = loss * mask\n","    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n","    return torch.mean(loss)\n","def masked_smape(preds, labels, null_val=np.nan):\n","    if np.isnan(null_val):\n","        mask = ~torch.isnan(labels)\n","    else:\n","        mask = (labels!=null_val)\n","    mask = mask.float()\n","    mask /=  torch.mean((mask))\n","    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n","    #loss = torch.abs(preds-labels)/labels\n","    loss = 2.0 * (torch.abs(preds - labels) / (torch.abs(preds) + torch.abs(labels)))\n","    loss = loss * mask\n","    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n","    return torch.mean(loss)\n","\n","def metric(pred, real):\n","    mae = masked_mae(pred,real,0.0).item()\n","    mape = masked_mape(pred,real,0.0).item()\n","    rmse = masked_rmse(pred,real,0.0).item()\n","    smape = masked_smape(pred,real,0.0).item()\n","    return mae,mape,rmse,smape"]},{"cell_type":"markdown","metadata":{"id":"r4fdCQ3TANli"},"source":["### Layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8DYHAPCANli"},"outputs":[],"source":["\n","class nconv(nn.Module):\n","    def __init__(self):\n","        super(nconv,self).__init__()\n","\n","    def forward(self,x, A):\n","        x = torch.einsum('ncwl,vw->ncvl',(x,A))  # adj的row為鄰接=>橫向聚合\n","        return x.contiguous()\n","\n","\n","class linear(nn.Module):\n","    def __init__(self,c_in,c_out,bias=True):\n","        super(linear,self).__init__()\n","        self.mlp = torch.nn.Conv2d(c_in, c_out, kernel_size=(1, 1), padding=(0,0), stride=(1,1), bias=bias)\n","\n","    def forward(self,x):\n","        return self.mlp(x)\n","\n","\n","class LayerNorm(nn.Module):\n","    __constants__ = ['normalized_shape', 'weight', 'bias', 'eps', 'elementwise_affine']\n","    def __init__(self, normalized_shape, eps=1e-5, elementwise_affine=True):\n","        super(LayerNorm, self).__init__()\n","        if isinstance(normalized_shape, numbers.Integral):\n","            normalized_shape = (normalized_shape,)\n","        self.normalized_shape = tuple(normalized_shape)\n","        self.eps = eps\n","        self.elementwise_affine = elementwise_affine\n","        if self.elementwise_affine:\n","            self.weight = nn.Parameter(torch.Tensor(*normalized_shape))\n","            self.bias = nn.Parameter(torch.Tensor(*normalized_shape))\n","        else:\n","            self.register_parameter('weight', None)\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","\n","\n","    def reset_parameters(self):\n","        if self.elementwise_affine:\n","            init.ones_(self.weight)\n","            init.zeros_(self.bias)\n","\n","    def forward(self, input, idx):\n","        if self.elementwise_affine:\n","            return F.layer_norm(input, tuple(input.shape[1:]), self.weight[:,idx,:], self.bias[:,idx,:], self.eps)\n","        else:\n","            return F.layer_norm(input, tuple(input.shape[1:]), self.weight, self.bias, self.eps)\n","\n","    def extra_repr(self):\n","        return '{normalized_shape}, eps={eps}, ' \\\n","            'elementwise_affine={elementwise_affine}'.format(**self.__dict__)"]},{"cell_type":"markdown","metadata":{"id":"Zj28SSNSLeij"},"source":["### Multivariate View"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSWxIXotLg10"},"outputs":[],"source":["\n","\n","# this efficient implementation comes from https://github.com/xptree/DeepInf/\n","class F_BatchMultiHeadGraphAttention(nn.Module):\n","    def __init__(self, n_heads, num_nodes, dropout, bias=True):\n","        super(F_BatchMultiHeadGraphAttention, self).__init__()\n","\n","        print('F_BatchMultiHeadGraphAttention', n_heads, num_nodes, dropout)\n","        self.n_head = n_heads\n","        self.f_in = num_nodes\n","        #self.w = nn.Parameter(torch.Tensor(self.n_head, num_nodes, num_nodes))\n","        self.a_src = nn.Parameter(torch.Tensor(self.n_head, num_nodes, 1))\n","        self.a_dst = nn.Parameter(torch.Tensor(self.n_head, num_nodes, 1))\n","\n","        self.mlp_convs = (nn.Conv2d(n_heads, n_heads, 1))\n","\n","        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.dropout = nn.Dropout(dropout)\n","        if bias:\n","            self.bias = nn.Parameter(torch.Tensor(num_nodes))\n","            nn.init.constant_(self.bias, 0)\n","        else:\n","            self.register_parameter(\"bias\", None)\n","\n","        nn.init.xavier_uniform_(self.a_src, gain=1.414)\n","        nn.init.xavier_uniform_(self.a_dst, gain=1.414)\n","\n","    def forward(self, h):\n","        bs, ch, n, dim = h.size()\n","        h_prime = (h)\n","        attn_src = torch.matmul(torch.tanh(h), self.a_src)\n","        attn_dst = torch.matmul(torch.tanh(h), self.a_dst)\n","        attn = attn_src.expand(-1, -1, -1, n) + attn_dst.expand(-1, -1, -1, n).permute(\n","            0, 1, 3, 2\n","        )\n","        attn = self.leaky_relu(attn)\n","        attn = self.softmax(attn)\n","        attn = self.dropout(attn)\n","        output = torch.matmul(attn, h_prime)\n","        return output, attn\n","\n","\n","class Fusion(nn.Module):\n","    def __init__(self, kern, dilation_factor, n_heads, num_nodes, mlp, mlp2, dropout):\n","        super(Fusion, self).__init__()\n","\n","        self.gat_layer = F_BatchMultiHeadGraphAttention(\n","            n_heads, num_nodes, dropout\n","        )\n","        self.gat_layer2 = F_BatchMultiHeadGraphAttention(\n","            n_heads, num_nodes, dropout\n","        )\n","\n","        self.mlp1 = (nn.Conv2d(32,8,(1, 1),dilation=(1,1)))\n","        self.mlp2 = (nn.Conv2d(32,8,(1, 1),dilation=(1,1)))\n","        self.mlp3 = (nn.Conv2d(32,8,(1, 1),dilation=(1,1)))\n","        self.mlp4 = (nn.Conv2d(32,8,(1, 1),dilation=(1,1)))\n","        self.mlp5 = (nn.Conv2d(32,8,(1, 1),dilation=(1,1)))\n","        self.mlp6 = (nn.Conv2d(32,8,(1, 1),dilation=(1,1)))\n","\n","\n","        self.mlp7 = (nn.Conv2d(16,32,(1, 1),dilation=(1,1)))\n","    def forward(self,x_input, diff1, diff2, x1, x2):\n","\n","        bs,c,n,t = x_input.shape\n","        x_input_cpy = x_input\n","\n","        x_input1 = self.mlp1(x_input)\n","        diff1 = self.mlp2(diff1)\n","        diff2 = self.mlp3(diff2)\n","\n","        x_input2 = self.mlp4(x_input)\n","        x1 = self.mlp5(x1)\n","        x2 = self.mlp6(x2)\n","\n","        bs,c,n,t = x1.shape\n","        x_input_new = []\n","        x1_all = []\n","        x2_all = []\n","        for i in range(t):\n","          x_t = (torch.cat([x_input1[:,:,:,[i]], diff1[:,:,:,[i]], diff2[:,:,:,[i]]], dim=3)).permute(0,1,3,2)\n","          x_all, attn = self.gat_layer( x_t )\n","\n","\n","          x_t = (torch.cat([x_input2[:,:,:,[i]], x1[:,:,:,[i]], x2[:,:,:,[i]]], dim=3)).permute(0,1,3,2)\n","          x_all2, attn = self.gat_layer2( x_t )\n","\n","          x1_all.append(x_all[:,:,[0]].permute(0,1,3,2))\n","          x2_all.append(x_all2[:,:,[0]].permute(0,1,3,2))\n","\n","        x1 = torch.cat(x1_all,dim=3)\n","        x2 = torch.cat(x2_all,dim=3)\n","\n","        x_out = self.mlp7( torch.cat([x1,x2],dim=1) )+x_input_cpy\n","\n","\n","        return x_out"]},{"cell_type":"markdown","metadata":{"id":"8B9xb-GQJ9e_"},"source":["### Temporal View"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"code","id":"PrAmVAqYJ9fA"},"outputs":[],"source":["import numpy as np\n","\n","def create_matrix(n, k):\n","    mat = np.zeros((n, n))\n","    for i in range(n):\n","        for j in range(k):\n","            if i-j >= 0:\n","                mat[i][i-j] = 1\n","    return mat\n","\n","\n","# this efficient implementation comes from https://github.com/xptree/DeepInf/\n","class BatchMultiHeadGraphAttention(nn.Module):\n","    def __init__(self, n_heads, num_nodes, dropout, bias=True):\n","        super(BatchMultiHeadGraphAttention, self).__init__()\n","\n","        print('BatchMultiHeadGraphAttention', n_heads, num_nodes, dropout)\n","        self.n_head = n_heads\n","        self.f_in = num_nodes\n","        #self.w = nn.Parameter(torch.Tensor(self.n_head, num_nodes, num_nodes))\n","        self.a_src = nn.Parameter(torch.Tensor(self.n_head, num_nodes, 1))\n","        self.a_dst = nn.Parameter(torch.Tensor(self.n_head, num_nodes, 1))\n","\n","        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.dropout = nn.Dropout(dropout)\n","        if bias:\n","            self.bias = nn.Parameter(torch.Tensor(num_nodes))\n","            nn.init.constant_(self.bias, 0)\n","        else:\n","            self.register_parameter(\"bias\", None)\n","\n","        #nn.init.xavier_uniform_(self.w, gain=1.414)\n","        nn.init.xavier_uniform_(self.a_src, gain=1.414)\n","        nn.init.xavier_uniform_(self.a_dst, gain=1.414)\n","\n","    def forward(self, h):\n","\n","        bs, ch, n, dim = h.size()\n","        #h_prime = torch.matmul(h, self.w)\n","        h_prime = h\n","        attn_src = torch.matmul(h, self.a_src)\n","        attn_dst = torch.matmul(h, self.a_dst)\n","        attn = attn_src.expand(-1, -1, -1, n) + attn_dst.expand(-1, -1, -1, n).permute(\n","            0, 1, 3, 2\n","        )\n","\n","        attn = self.leaky_relu(attn)\n","        attn = self.softmax(attn)\n","        attn = self.dropout(attn)\n","        output = torch.matmul(attn, h_prime)\n","\n","        return output, attn\n","\n","# MutiChannel_GAT(kern, dilation_factor, n_heads, num_nodes, mlp, mlp2, dropout)\n","class MutiChannel_GAT(nn.Module):\n","    def __init__(self, kern, dilation_factor, n_heads, num_nodes, mlp, mlp2, dropout):\n","        super(MutiChannel_GAT, self).__init__()\n","\n","        print('MutiChannel_GAT', n_heads, num_nodes, dropout)\n","\n","        self.gat_layer1 = BatchMultiHeadGraphAttention(\n","            n_heads*2, num_nodes, dropout\n","        )\n","\n","        self.gat_layer4 = BatchMultiHeadGraphAttention(\n","            n_heads*2, num_nodes, dropout\n","        )\n","\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.1)\n","\n","        self.mlp1 = (nn.Conv2d(32,16,(2, 1),dilation=(1,1)))\n","        self.mlp4 = (nn.Conv2d(32,16,(5, 1),dilation=(1,1)))\n","\n","    def forward(self,x_input):\n","\n","        x_input_cpy = x_input\n","\n","        x_input1 = self.mlp1(x_input)\n","        x_input4 = self.mlp4(x_input)\n","\n","        #-------------GAT-------------#\n","        x_input1, attn = self.gat_layer1(x_input1)\n","        x_input4, attn = self.gat_layer4(x_input4)\n","        #-------------GAT-------------#\n","\n","        x_input = torch.cat([x_input1[:,:,-x_input4.size(2):],x_input4[:,:,-x_input4.size(2):]], dim=1)\n","\n","        x_input = ((x_input_cpy)[:,:,-x_input.size(2):] + (x_input)).permute(0,1,3,2)\n","\n","        return x_input\n"]},{"cell_type":"markdown","metadata":{"id":"4v1XVDNqlJzz"},"source":["### Spatial View"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8D1cMi41lMGF"},"outputs":[],"source":["import numpy as np\n","\n","def create_matrix(n, k):\n","    mat = np.zeros((n, n))\n","    for i in range(n):\n","        for j in range(k):\n","            if i-j >= 0:\n","                mat[i][i-j] = 1\n","    return mat\n","\n","\n","def pearson_corr2(tensor): # all: (64,1,n,dim)\n","  # Input tensor shape: (batch_size, num_nodes, time_steps)\n","  batch_size, num_nodes, _ = tensor.shape\n","  tensor = tensor - tensor.mean(dim=2, keepdim=True)\n","  std = tensor.std(dim=2, keepdim=True)\n","  tensor = tensor / (std + 1e-8)\n","  correlation_matrix = torch.matmul(tensor, tensor.transpose(1, 2))\n","  correlation_matrix = correlation_matrix / (tensor.shape[2] - 1)\n","  return correlation_matrix\n","\n","\n","def topK(attn, top_num ):\n","\n","  # Get the top K values and their indices for each row\n","  top_k_values, top_k_indices = attn.topk(top_num, dim=3)\n","\n","  # Create a mask with the same shape as the input tensor, filled with zeros\n","  mask = torch.zeros_like(attn)\n","\n","  # Set the top K values in the mask to 1\n","  mask.scatter_(3, top_k_indices, 1)\n","\n","  # Multiply the input tensor with the mask to get the result\n","  attn = attn * mask\n","\n","  return  attn\n","\n","# this efficient implementation comes from https://github.com/xptree/DeepInf/\n","class S_BatchMultiHeadGraphAttention(nn.Module):\n","    def __init__(self, n_heads, num_nodes, dropout, bias=True):\n","        super(S_BatchMultiHeadGraphAttention, self).__init__()\n","\n","        print('S_BatchMultiHeadGraphAttention', n_heads, num_nodes, dropout)\n","        self.n_head = n_heads\n","        self.f_in = num_nodes\n","        self.w = nn.Parameter(torch.Tensor(self.n_head*2, 1, 40))\n","        self.w2 = nn.Parameter(torch.Tensor(self.n_head*2, 40, 1))\n","\n","        self.a_src = nn.Parameter(torch.Tensor(self.n_head*2, 40, 1))\n","        self.a_dst = nn.Parameter(torch.Tensor(self.n_head*2, 40, 1))\n","\n","        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.dropout = nn.Dropout(dropout)\n","        if bias:\n","            self.bias = nn.Parameter(torch.Tensor(num_nodes))\n","            nn.init.constant_(self.bias, 0)\n","        else:\n","            self.register_parameter(\"bias\", None)\n","\n","        nn.init.xavier_uniform_(self.w, gain=1.414)\n","        nn.init.xavier_uniform_(self.w2, gain=1.414)\n","        nn.init.xavier_uniform_(self.a_src, gain=1.414)\n","        nn.init.xavier_uniform_(self.a_dst, gain=1.414)\n","\n","    def forward(self, h, a):\n","\n","\n","        bs, ch, n, dim = h.size()\n","        attn_src = torch.matmul(self.leaky_relu(torch.matmul(h, self.w)), self.a_src)\n","        attn_dst = torch.matmul(self.leaky_relu(torch.matmul(h, self.w)), self.a_dst)\n","        attn = attn_src.expand(-1, -1, -1, n) + attn_dst.expand(-1, -1, -1, n).permute(\n","            0, 1, 3, 2\n","        )\n","\n","\n","        attn_2 = self.leaky_relu(attn)\n","        attn_2 = self.softmax(attn_2)\n","        attn_2 = self.dropout(attn_2)\n","\n","        if len(a)>0:\n","\n","          attn_2 = (attn_2+a)/2\n","        else:\n","          attn_2 = attn_2\n","\n","        output_2 = torch.matmul(attn_2, h)\n","\n","        return output_2, attn\n","\n","# MutiChannel_GAT(kern, dilation_factor, n_heads, num_nodes, mlp, mlp2, dropout)\n","class S_MutiChannel_GAT(nn.Module):\n","    def __init__(self, kern, dilation_factor, n_heads, num_nodes, mlp, mlp2, dropout):\n","        super(S_MutiChannel_GAT, self).__init__()\n","\n","        print('S_MutiChannel_GAT', n_heads, num_nodes, dropout)\n","\n","        self.gat_layer = S_BatchMultiHeadGraphAttention(\n","            n_heads, num_nodes, dropout\n","        )\n","        self.gat_layer2 = S_BatchMultiHeadGraphAttention(\n","            n_heads, num_nodes, dropout\n","        )\n","\n","\n","        self.mlp1 =  nn.Conv2d(in_channels=32,\n","                                    out_channels=16,\n","                                    kernel_size=(1, 1))\n","\n","        self.mlp2 =  nn.Conv2d(in_channels=16*3,\n","                                    out_channels=16,\n","                                    kernel_size=(1, 1))\n","\n","    def forward(self,x_input, a_f, a_b):\n","        x_input_cpy = x_input\n","\n","        x = x_input\n","\n","        xf= x_input\n","\n","        bs,c,n,t = xf.shape\n","        x1_all = []\n","        x2_all = []\n","        x3_all = []\n","        x4_all = []\n","        for i in range(t):\n","          x_in = xf[...,[i]]\n","\n","          x1, attn = self.gat_layer(x_in,a_f)\n","\n","          x2, attn = self.gat_layer2((x1),[])\n","          x1_all.append(x1)\n","          x2_all.append(x2)\n","\n","\n","        x1 = torch.cat(x1_all,dim=3)\n","        x2 = torch.cat(x2_all,dim=3)\n","\n","        x_out = self.mlp2(torch.cat([xf,x1,x2],dim=1))\n","\n","        return x_out"]},{"cell_type":"markdown","metadata":{"id":"jenRSFIeANli"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SEryDF5qANli"},"outputs":[],"source":["class MFGM(nn.Module):\n","    def __init__(self, model_type, gcn_true, buildA_true, gcn_depth, num_nodes, device, predefined_A=None,kernel_set=None, static_feat=None, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=1, conv_channels=32, residual_channels=32, skip_channels=64, end_channels=128, seq_length=12, in_dim=2, out_dim=12, layers=3, propalpha=0.05, tanhalpha=3, layer_norm_affline=True):\n","        super(MFGM, self).__init__()\n","\n","        self.model_type = model_type\n","\n","        self.gcn_true = gcn_true\n","        self.buildA_true = buildA_true\n","        self.num_nodes = num_nodes\n","        self.dropout = dropout\n","        self.predefined_A = predefined_A\n","        self.layers = layers\n","        self.seq_length = seq_length\n","\n","        self.filter_convs = nn.ModuleList()\n","        self.gate_convs = nn.ModuleList()\n","        #----------------------#\n","        self.filter_convs1 = nn.ModuleList()\n","        self.gate_convs1 = nn.ModuleList()\n","        self.filter_convs2 = nn.ModuleList()\n","        self.gate_convs2 = nn.ModuleList()\n","        #----------------------#\n","\n","\n","        self.residual_convs = nn.ModuleList()\n","        self.skip_convs = nn.ModuleList()\n","        self.gconv1 = nn.ModuleList()\n","        self.gconv2 = nn.ModuleList()\n","        self.norm = nn.ModuleList()\n","\n","        #----------------------#\n","        self.gconv1_1 = nn.ModuleList()\n","        self.gconv1_2 = nn.ModuleList()\n","\n","        self.gconv2_1 = nn.ModuleList()\n","        self.gconv2_2 = nn.ModuleList()\n","\n","        self.norm1 = nn.ModuleList()\n","        self.norm2 = nn.ModuleList()\n","\n","        self.fusion = nn.ModuleList()\n","        #----------------------#\n","\n","        self.start_conv = nn.Conv2d(in_channels=in_dim,\n","                                    out_channels=residual_channels,\n","                                    kernel_size=(1, 1))\n","        self.start_conv1 = nn.Conv2d(in_channels=in_dim,\n","                                    out_channels=residual_channels,\n","                                    kernel_size=(1, 1))\n","        self.start_conv2 = nn.Conv2d(in_channels=in_dim,\n","                                    out_channels=residual_channels,\n","                                    kernel_size=(1, 1))\n","\n","        self.start_conv3 = nn.Conv2d(in_channels=in_dim,\n","                                    out_channels=residual_channels,\n","                                    kernel_size=(1, 1))\n","        self.start_conv4 = nn.Conv2d(in_channels=in_dim,\n","                                    out_channels=residual_channels,\n","                                    kernel_size=(1, 1))\n","\n","        dilation_factor = 1\n","        n_heads = 8\n","        kern = 6\n","        self.fusion = (Fusion(kern, dilation_factor, n_heads, 21, [24,16,8], [24,32], dropout))\n","\n","        # Paepr eq 11: R=1+(c-1)(q^m -1)/(q -1).\n","        kernel_size = 7\n","        if dilation_exponential>1:\n","            self.receptive_field = int(1+(kernel_size-1)*(dilation_exponential**layers-1)/(dilation_exponential-1))\n","        else:\n","            self.receptive_field = layers*(kernel_size-1) + 1\n","\n","        print(\"# Model Type\", self.model_type)\n","        print(\"# receptive_field\", self.receptive_field)\n","        i=0\n","        if dilation_exponential>1:\n","            rf_size_i = int(1 + i*(kernel_size-1)*(dilation_exponential**layers-1)/(dilation_exponential-1))\n","        else:\n","            rf_size_i = i*layers*(kernel_size-1)+1\n","        new_dilation = 1\n","\n","        self.receptive_field = 13\n","        temporal_len = self.receptive_field\n","        for j in range(1,layers+1):\n","\n","            if dilation_exponential > 1:\n","                rf_size_j = int(rf_size_i + (kernel_size-1)*(dilation_exponential**j-1)/(dilation_exponential-1))\n","            else:\n","                rf_size_j = rf_size_i+j*(kernel_size-1)\n","\n","            kern = 5\n","            dilation_factor = 1\n","            n_heads = 8\n","            #num_nodes = temporal_len\n","            print('temporal_len', temporal_len)\n","            self.filter_convs.append(MutiChannel_GAT(kern, dilation_factor, n_heads, num_nodes, [24,16,8], [32,32], dropout))\n","            self.gate_convs.append(MutiChannel_GAT(kern, dilation_factor, n_heads, num_nodes, [24,16,8], [32,32], dropout))\n","\n","\n","            temporal_len = temporal_len-(kern-1)\n","\n","            '''\n","            # skip_convs #\n","            (0): Conv2d(32, 64, kernel_size=(1, 13), stride=(1, 1))\n","            (1): Conv2d(32, 64, kernel_size=(1, 7), stride=(1, 1))\n","            (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n","            '''\n","            if self.seq_length>self.receptive_field:\n","                self.skip_convs.append(nn.Conv2d(in_channels=conv_channels,\n","                                                out_channels=skip_channels,\n","                                                kernel_size=(1, temporal_len)))\n","            else:\n","                self.skip_convs.append(nn.Conv2d(in_channels=conv_channels,\n","                                                out_channels=skip_channels,\n","                                                kernel_size=(1, temporal_len)))\n","            dilation_factor = 1\n","            n_heads = 8\n","\n","            self.gconv1.append(S_MutiChannel_GAT(kern, dilation_factor, n_heads, temporal_len, [24,16,8], [16,24,32], dropout))\n","            self.gconv2.append(S_MutiChannel_GAT(kern, dilation_factor, n_heads, temporal_len, [24,16,8], [16,24,32], dropout))\n","\n","\n","\n","\n","            #####   Normalization   ##### START\n","            if self.seq_length>self.receptive_field:\n","                print('1', self.seq_length - rf_size_j + 1)\n","                self.norm.append(LayerNorm((residual_channels, num_nodes, temporal_len),elementwise_affine=layer_norm_affline))\n","\n","            else:\n","                print('2', self.receptive_field - rf_size_j + 1)\n","                self.norm.append(LayerNorm((residual_channels, num_nodes, temporal_len),elementwise_affine=layer_norm_affline))\n","\n","            #####   Normalization   ##### END\n","\n","\n","\n","\n","            new_dilation *= dilation_exponential\n","\n","\n","\n","        self.end_conv_1 = nn.Conv2d(in_channels=skip_channels,\n","                                             out_channels=end_channels,\n","                                             kernel_size=(1,1),\n","                                             bias=True)\n","        self.end_conv_2 = nn.Conv2d(in_channels=end_channels,\n","                                             out_channels=out_dim,\n","                                             kernel_size=(1,1),\n","                                             bias=True)\n","\n","        #####   SKIP layer   ##### START\n","        '''\n","        (skip0): Conv2d(2, 64, kernel_size=(1, 19), stride=(1, 1))\n","        (skipE): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n","        '''\n","        if self.seq_length > self.receptive_field:\n","            self.skip0 = nn.Conv2d(in_channels=in_dim, out_channels=skip_channels, kernel_size=(1, self.seq_length), bias=True)\n","            self.skipE = nn.Conv2d(in_channels=residual_channels, out_channels=skip_channels, kernel_size=(1, self.seq_length-self.receptive_field+1), bias=True)\n","\n","        else:\n","            self.skip0 = nn.Conv2d(in_channels=in_dim, out_channels=skip_channels, kernel_size=(1, self.receptive_field), bias=True)\n","            self.skipE = nn.Conv2d(in_channels=residual_channels, out_channels=skip_channels, kernel_size=(1, 1), bias=True)\n","        #####   SKIP layer   ##### END\n","\n","        self.idx = torch.arange(self.num_nodes).to(device)\n","\n","\n","    def forward(self, input, input_1, input_2, idx=None):\n","        seq_len = input.size(3)\n","        assert seq_len==self.seq_length, 'input sequence length not equal to preset sequence length'\n","\n","\n","        # Step0: 檢查receptive_field, 不足則padding0\n","        if self.seq_length<self.receptive_field:\n","            input = nn.functional.pad(input,(self.receptive_field-self.seq_length,0,0,0))\n","            input_1 = nn.functional.pad(input_1,(self.receptive_field-self.seq_length,0,0,0))\n","            input_2 = nn.functional.pad(input_2,(self.receptive_field-self.seq_length,0,0,0))\n","\n","        # Step1: turn([64, 2, 207, 19]) to ([64, 32, 207, 19])\n","        x = self.start_conv(input)\n","\n","        diff_1 = torch.cat([(input[:,[0]]-input_1[:,[0]]),input[:,[1]]], dim=1)\n","        diff_2 = torch.cat([(input[:,[0]]-input_2[:,[0]]),input[:,[1]]], dim=1)\n","\n","        diff_1 = self.start_conv1(diff_1)\n","        diff_2 = self.start_conv2(diff_2)\n","\n","        x1 = self.start_conv3(input_1)\n","        x2 = self.start_conv4(input_2)\n","\n","        x = self.fusion(x,diff_1,diff_2,x1,x2)\n","\n","        # Step1-1: original input skip =>(skip0)\n","        # (skip0): Conv2d(2, 64, kernel_size=(1, 19), stride=(1, 1))\n","        # ([64, 32, 207, 19]) -> ([64, 64, 207, 1])\n","        skip = self.skip0(F.dropout(input, self.dropout, training=self.training))\n","\n","\n","        # Layers : 3層 : 19->13->7->1 (取決於TCN取的維度)\n","        for i in range(self.layers):\n","\n","            # Step2: Temporal Model --START #\n","            # 為上一層輸出, ex:  [64, 32, 207, 19] -> [64, 32, 207, 13] -> [64, 32, 207, 7]-> [64, 32, 207, 1]\n","            residual = x\n","\n","\n","            x = x.permute(0,1,3,2)\n","            # Tanh\n","            filter = self.filter_convs[i](x)\n","            filter = torch.tanh(filter)\n","\n","            # Sigmoid\n","            gate = self.gate_convs[i](x)\n","            gate = torch.sigmoid(gate)\n","\n","            # Fusion\n","            x = filter * gate\n","\n","            #-----------------#\n","\n","\n","            x = F.dropout(x, self.dropout, training=self.training)\n","\n","            s = x\n","            #s = self.fusion[i](x,x1,x2)\n","            s = self.skip_convs[i](s)\n","\n","            skip = s + skip\n","\n","            # Step3: Skip after TCN --END #\n","\n","            x = torch.cat([self.gconv1[i](x[:,:16], self.predefined_A[0], self.predefined_A[1]), self.gconv2[i](x[:,16:32], self.predefined_A[0], self.predefined_A[1])], dim=1 )\n","\n","            x = x + residual[:, :, :, -x.size(3):]\n","\n","\n","            if idx is None:\n","                x = self.norm[i](x,self.idx)\n","\n","            else:\n","                x = self.norm[i](x,idx)\n","\n","            # Step4: GCN --END #\n","\n","        #(skipE): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n","        skip = self.skipE(x) + skip\n","\n","        x = F.relu(skip)\n","        x = F.relu(self.end_conv_1(x))\n","        x = self.end_conv_2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"fbowdbREANli"},"source":["### Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTga9hrXANli"},"outputs":[],"source":["class Trainer():\n","    def __init__(self, model, lrate, wdecay, clip, step_size, seq_out_len, scaler, device, cl=True):\n","        self.scaler = scaler\n","        self.model = model\n","        self.model.to(device)\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=lrate, weight_decay=wdecay)\n","        self.loss = masked_mae\n","        self.clip = clip\n","\n","        self.step = step_size\n","        self.iter = 1\n","        self.task_level = 1\n","        self.seq_out_len = seq_out_len\n","        self.cl = cl\n","\n","    def train(self, input, real_val, input_1, input_2, idx=None):\n","        self.model.train()\n","        self.optimizer.zero_grad()\n","        output = self.model(input, input_1, input_2, idx=idx)\n","        output = output.transpose(1,3)\n","        real = torch.unsqueeze(real_val,dim=1)\n","\n","        predict = self.scaler.inverse_transform(output)\n","\n","        if self.iter%self.step==0 and self.task_level<=self.seq_out_len:\n","            self.task_level +=1\n","            print(\"### cl learning\\n iter\",self.iter,\"\\niter%step\",self.iter%self.step,\"\\ntask_level\",self.task_level)\n","            print(\"# predict len:\", len(predict[:, :, :, :self.task_level]))\n","\n","        if self.cl:\n","            loss = masked_mae(predict[:, :, :, :self.task_level], real[:, :, :, :self.task_level], 0.0)\n","        else:\n","            loss = masked_mae(predict, real, 0.0)\n","\n","        loss.backward()\n","\n","        if self.clip is not None:\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n","\n","        self.optimizer.step()\n","        mae = masked_mae(predict,real,0.0).item()\n","        mape = masked_mape(predict,real,0.0).item()\n","        rmse = masked_rmse(predict,real,0.0).item()\n","        smape = masked_smape(predict,real,0.0).item()\n","        self.iter += 1\n","        return mae,mape,rmse,smape\n","\n","    def eval(self, input,  real_val, input_1, input_2):\n","        self.model.eval()\n","\n","        output = self.model(input, input_1, input_2)\n","        output = output.transpose(1,3)\n","        real = torch.unsqueeze(real_val,dim=1)\n","        #predict = self.scaler.inverse_transform(output)\n","        #predict = self.scaler.inverse_transform(output)\n","\n","        '''\n","        predict = output\n","\n","        for i in range(args.num_nodes):\n","          predict[:,0,i,:] = self.scaler[i].inverse_transform(predict[:,0,i,:])\n","        '''\n","        predict = self.scaler.inverse_transform(output)\n","\n","        loss = self.loss(predict, real, 0.0)\n","        mape = masked_mape(predict,real,0.0).item()\n","        rmse = masked_rmse(predict,real,0.0).item()\n","        smape = masked_smape(predict,real,0.0).item()\n","        return loss.item(),mape,rmse,smape\n"]},{"cell_type":"markdown","metadata":{"id":"_84y8rqsANlj"},"source":["### Parameter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UQX_bh_FANlj"},"outputs":[],"source":["\n","\n","def str_to_bool(value):\n","    if isinstance(value, bool):\n","        return value\n","    if value.lower() in {'false', 'f', '0', 'no', 'n'}:\n","        return False\n","    elif value.lower() in {'true', 't', '1', 'yes', 'y'}:\n","        return True\n","    raise ValueError(f'{value} is not a valid boolean value')\n","\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--device',type=str,default='cuda',help='')\n","parser.add_argument('--adjtype',type=str,default='doubletransition',help='adj type')\n","\n","\n","parser.add_argument('--gcn_true', type=str_to_bool, default=True, help='whether to add graph convolution layer')\n","parser.add_argument('--buildA_true', type=str_to_bool, default=True,help='whether to construct adaptive adjacency matrix')\n","\n","parser.add_argument('--cl', type=str_to_bool, default=True,help='whether to do curriculum learning')\n","\n","parser.add_argument('--gcn_depth',type=int,default=2,help='graph convolution depth')\n","\n","parser.add_argument('--dropout',type=float,default=0.3,help='dropout rate')\n","parser.add_argument('--subgraph_size',type=int,default=20,help='k')\n","parser.add_argument('--node_dim',type=int,default=40,help='dim of nodes')\n","parser.add_argument('--dilation_exponential',type=int,default=1,help='dilation exponential')\n","\n","parser.add_argument('--conv_channels',type=int,default=32,help='convolution channels')\n","parser.add_argument('--residual_channels',type=int,default=32,help='residual channels')\n","\n","\n","parser.add_argument('--in_dim',type=int,default=2,help='inputs dimension')\n","parser.add_argument('--seq_in_len',type=int,default=12,help='input sequence length')\n","parser.add_argument('--seq_out_len',type=int,default=12,help='output sequence length')\n","\n","\n","parser.add_argument('--batch_size',type=int,default=64,help='batch size')\n","\n","parser.add_argument('--clip',type=int,default=5,help='clip')\n","\n","\n","parser.add_argument('--propalpha',type=float,default=0.05,help='prop alpha')\n","parser.add_argument('--tanhalpha',type=float,default=3,help='adj alpha')\n","\n","\n","parser.add_argument('--model_type',type=str,default='MFGM',help='model type')\n","parser.add_argument('--skip_channels',type=int,default=64,help='skip channels')\n","parser.add_argument('--end_channels',type=int,default=128,help='end channels')\n","parser.add_argument('--layers',type=int,default=3,help='number of layers')\n","parser.add_argument('--kernel_set',default=[2,5], type=int, nargs='+')\n","\n","\n","\n","parser.add_argument('--print_every',type=int,default=50,help='')\n","parser.add_argument('--seed',type=int,default=101,help='random seed')\n","parser.add_argument('--save',type=str,default='./save/',help='save path')\n","\n","parser.add_argument('--log_print', type=str_to_bool, default=False ,help='whether to load static feature')\n","\n","parser.add_argument('--learning_rate',type=float,default=0.0005,help='learning rate')\n","parser.add_argument('--weight_decay',type=float,default=0.0001,help='weight decay rate')\n","\n","parser.add_argument('--step_size1',type=int,default=800,help='step_size')\n","parser.add_argument('--step_size2',type=int,default=100,help='step_size')\n","\n","target = 'hsin-2022-21nodes'\n","parser.add_argument('--data',type=str,default='../Data/'+target ,help='data path')\n","parser.add_argument('--adj_data',type=str,default='../Data/'+target+'/adj_mat_2022_hsin_21_locs.pkl',help='adj data path')\n","parser.add_argument('--num_nodes',type=int,default=21,help='number of nodes/variables')\n","\n","parser.add_argument('--expid',type=int,default=202304201422,help='experiment id')\n","parser.add_argument('--runs',type=int,default=10,help='number of runs')\n","parser.add_argument('--epochs',type=int,default=200,help='')\n","\n","#args = parser.parse_args()\n","args=parser.parse_args(args=[])\n","torch.set_num_threads(3)\n","\n","#args = parser.parse_args()\n","args=parser.parse_args(args=[])\n","print('# args', args)\n","\n","device = torch.device(args.device)\n","\n","writer = SummaryWriter()"]},{"cell_type":"markdown","metadata":{"id":"QRD8IwnmANlj"},"source":["### Loading Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUl-Eg70ANlj"},"outputs":[],"source":["\n","batch_size = args.batch_size\n","valid_batch_size = args.batch_size\n","test_batch_size = args.batch_size\n","data = {}\n","\n","type_list = ['vehicular', 'stationary', 'pedestrian']\n","\n","for i in range(len(type_list)):\n","\n","  for category in ['train', 'val', 'test']:\n","\n","      # Loading npz\n","      cat_data = np.load(os.path.join(args.data, category+\"_\"+type_list[i] + '.npz'))\n","      print(\"loading:\", category+\"_\"+type_list[i] + '.npz')\n","\n","      if i == 0:\n","        key = \"\"\n","      else:\n","        key = \"_\"+str(i)\n","      data['x_' + category+key] = cat_data['x']     # (?, 12, 207, 2)\n","      data['y_' + category+key] = cat_data['y']     # (?, 12, 207, 2)\n","\n","print(data.keys())\n","\n","\n","# 使用train的mean/std來正規化valid/test #\n","scaler = StandardScaler(mean=data['x_train'][..., 0].mean(), std=data['x_train'][..., 0].std())\n","\n","# 將欲訓練特徵改成正規化\n","for i in range(len(type_list)):\n","  if i == 0:\n","    key = \"\"\n","  else:\n","    key = \"_\"+str(i)\n","\n","  for category in ['train', 'val', 'test']:\n","    data['x_' + category+key][..., 0] = scaler.transform(data['x_' + category+key][..., 0])\n","\n","\n","data['train_loader'] = DataLoaderM(data['x_train'], data['y_train'], data['x_train_1'], data['x_train_2'], batch_size)\n","data['val_loader'] = DataLoaderM(data['x_val'], data['y_val'], data['x_val_1'], data['x_val_2'], valid_batch_size)\n","data['test_loader'] = DataLoaderM(data['x_test'], data['y_test'], data['x_test_1'], data['x_test_2'], test_batch_size)\n","data['scaler'] = scaler\n","\n","'''\n","adj_mx: 根據distances_la_2012.csv, 找出每個sensor與其他sensor距離並建立距離矩陣, 再進行正規化\n","'''\n","sensor_ids, sensor_id_to_ind, adj_mx = load_adj(args.adj_data,args.adjtype)   # adjtype: default='doubletransition'\n","\n","adj_mx = [torch.tensor(i).to(device) for i in adj_mx]\n","\n","dataloader = data.copy()\n"]},{"cell_type":"markdown","metadata":{"id":"IDMPtPrdANlj"},"source":["### Main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4NI54XAEgydV"},"outputs":[],"source":["\n","\n","def main(runid):\n","\n","\n","    # if args.load_static_feature:\n","    #     static_feat = load_node_feature('data/sensor_graph/location.csv')\n","    # else:\n","    #     static_feat = None\n","\n","    model = MFGM(args.model_type, args.gcn_true, args.buildA_true, args.gcn_depth, args.num_nodes,\n","                   device, predefined_A=adj_mx, kernel_set=args.kernel_set, dropout=args.dropout, subgraph_size=args.subgraph_size, node_dim=args.node_dim, dilation_exponential=args.dilation_exponential, conv_channels=args.conv_channels, residual_channels=args.residual_channels,\n","                  skip_channels=args.skip_channels, end_channels= args.end_channels,\n","                  seq_length=args.seq_in_len, in_dim=args.in_dim, out_dim=args.seq_out_len,\n","                  layers=args.layers, propalpha=args.propalpha, tanhalpha=args.tanhalpha, layer_norm_affline=True)\n","\n","    print(model)\n","    print(args)\n","\n","    print('The recpetive field size is', model.receptive_field)\n","    nParams = sum([p.nelement() for p in model.parameters()])       # model參數量!\n","    print('Number of model parameters is', nParams)\n","\n","    engine = Trainer(model, args.learning_rate, args.weight_decay, args.clip, args.step_size1, args.seq_out_len, data['scaler'], device, args.cl)\n","\n","    print(\"start training...\",flush=True)\n","    his_loss =[]\n","    val_time = []\n","    train_time = []\n","    minl = 1e5\n","    start_epoch=0\n","    SAVE_PATH = \"\"\n","    train_loss_epoch = []  # 紀錄train在epoch收斂\n","    valid_loss_epoch = []  # 紀錄valid在epoch收斂\n","    \"\"\"\n","    ########------------------- 讀取檔案要處理的code -----------------------#############\n","    ### loading model ###\n","    SAVE_PATH = args.save + \"exp\"+str(args.expid)+\"_0.pth\"\n","\n","    checkpoint = torch.load(SAVE_PATH)\n","    engine.model.load_state_dict(checkpoint['model_state_dict'])\n","    engine.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    engine.task_level = checkpoint['task_level']\n","    start_epoch = checkpoint['epoch']\n","    #minl = checkpoint['loss']\n","    train_loss_epoch = checkpoint['train_loss']\n","    valid_loss_epoch = checkpoint['valid_loss']\n","    ### 測試讀取出的model ###\n","    valid_loss = []\n","    valid_mape = []\n","    valid_rmse = []\n","    for iter, (x, y) in enumerate(dataloader['val_loader'].get_iterator()):\n","        testx = torch.Tensor(x).to(device)\n","        testx = testx.transpose(1, 3)\n","        testy = torch.Tensor(y).to(device)\n","        testy = testy.transpose(1, 3)\n","        metrics = engine.eval(testx, testy[:,0,:,:])\n","        valid_loss.append(metrics[0])\n","        valid_mape.append(metrics[1])\n","        valid_rmse.append(metrics[2])\n","\n","    mvalid_loss = np.mean(valid_loss)\n","    mvalid_mape = np.mean(valid_mape)\n","    mvalid_rmse = np.mean(valid_rmse)\n","    print(\"### 2-The valid loss on loding model is\", str(round(mvalid_mape,4)))\n","    minl= mvalid_mape\n","    print(\"### minl:\",minl, \"checkpoint['loss']:\",checkpoint['loss'])\n","    ### 測試讀取出的model ###\n","    ########------------------- 讀取檔案要處理的code -----------------------#############\n","    \"\"\"\n","    '''\n","    #####\n","    SAVE_PATH = args.save + \"exp202111182244_0.pth\"\n","    checkpoint = torch.load(SAVE_PATH)\n","    engine.model.load_state_dict(checkpoint['model_state_dict'])\n","    engine.task_level = checkpoint['task_level']\n","    start_epoch = checkpoint['epoch']\n","    train_loss_epoch = checkpoint['train_loss']\n","    valid_loss_epoch = checkpoint['valid_loss']\n","    #####\n","    '''\n","    for i in range(start_epoch,start_epoch+args.epochs+1):\n","\n","        train_loss = []\n","        train_mape = []\n","        train_rmse = []\n","        train_smape = []\n","        t1 = time.time()\n","        dataloader['train_loader'].shuffle()  # 為了檢視資料先拿掉\n","        for iter, (x, y, x_1, x_2) in enumerate(dataloader['train_loader'].get_iterator()):\n","            trainx = torch.Tensor(x).to(device)\n","            trainx= trainx.transpose(1, 3)\n","            trainy = torch.Tensor(y).to(device)\n","            trainy = trainy.transpose(1, 3)\n","\n","            trainx_1 = torch.Tensor(x_1).to(device)\n","            trainx_1= trainx_1.transpose(1, 3)\n","\n","            trainx_2 = torch.Tensor(x_2).to(device)\n","            trainx_2= trainx_2.transpose(1, 3)\n","\n","            metrics = engine.train(trainx, trainy[:,0,:,:], trainx_1, trainx_2)\n","\n","            train_loss.append(metrics[0])\n","            train_mape.append(metrics[1])\n","            train_rmse.append(metrics[2])\n","            train_smape.append(metrics[3])\n","\n","            if iter % args.print_every == 0 :\n","                log = 'Iter: {:03d}, Train Loss: {:.4f}, Train MAPE: {:.4f}, Train RMSE: {:.4f}'\n","                print(log.format(iter, train_loss[-1], train_mape[-1], train_rmse[-1]),flush=True)\n","        t2 = time.time()\n","        train_time.append(t2-t1)\n","        #validation\n","        valid_loss = []\n","        valid_mape = []\n","        valid_rmse = []\n","        valid_smape = []\n","\n","        s1 = time.time()\n","        for iter, (x, y, x_1, x_2) in enumerate(dataloader['val_loader'].get_iterator()):\n","            testx = torch.Tensor(x).to(device)\n","            testx = testx.transpose(1, 3)\n","            testy = torch.Tensor(y).to(device)\n","            testy = testy.transpose(1, 3)\n","\n","            testx_1 = torch.Tensor(x_1).to(device)\n","            testx_1 = testx_1.transpose(1, 3)\n","            testx_2 = torch.Tensor(x_2).to(device)\n","            testx_2 = testx_2.transpose(1, 3)\n","\n","            metrics = engine.eval(testx, testy[:,0,:,:], testx_1, testx_2)\n","\n","            valid_loss.append(metrics[0])\n","            valid_mape.append(metrics[1])\n","            valid_rmse.append(metrics[2])\n","            valid_smape.append(metrics[3])\n","        s2 = time.time()\n","        log = 'Epoch: {:03d}, Inference Time: {:.4f} secs'\n","        print(log.format(i,(s2-s1)))\n","        val_time.append(s2-s1)\n","        mtrain_loss = np.mean(train_loss)\n","        mtrain_mape = np.mean(train_mape)\n","        mtrain_rmse = np.mean(train_rmse)\n","        mtrain_smape = np.mean(train_smape)\n","\n","        mvalid_loss = np.mean(valid_loss)\n","        mvalid_mape = np.mean(valid_mape)\n","        mvalid_rmse = np.mean(valid_rmse)\n","        mvalid_smape = np.mean(valid_smape)\n","        #his_loss.append(mvalid_loss)\n","        his_loss.append(mvalid_smape)\n","\n","        #writer.add_scalar(\"train_loss\", mtrain_loss, i)\n","        #writer.add_scalar(\"valid_loss\", mvalid_loss, i)\n","\n","        writer.add_scalar(\"train_loss\", mvalid_loss, i)\n","        writer.add_scalar(\"valid_loss\", mvalid_loss, i)\n","\n","\n","        log = 'Epoch: {:03d}, Train Loss: {:.4f}, Train MAPE: {:.4f}, Train RMSE: {:.4f}, Valid Loss: {:.4f}, Valid MAPE: {:.4f}, Valid RMSE: {:.4f}, Training Time: {:.4f}/epoch'\n","        print(log.format(i, mtrain_loss, mtrain_mape, mtrain_rmse, mvalid_loss, mvalid_mape, mvalid_rmse, (t2 - t1)),flush=True)\n","        # 紀錄每個epoch的loss\n","        train_loss_epoch.append(mtrain_loss)\n","        valid_loss_epoch.append(mvalid_loss)\n","\n","        '''\n","        if mvalid_loss<minl:\n","            torch.save(engine.model.state_dict(), args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\")\n","            minl = mvalid_loss\n","        '''\n","        if mvalid_loss<minl:\n","            target_best_model = args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\"\n","            print(\"### Update Best Model:\",target_best_model, 'Loss:', mvalid_mape, \" ###\")\n","            #torch.save(engine.model.state_dict(), args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\")\n","            SAVE_PATH = args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\"\n","            torch.save({\n","              'epoch': i,\n","              'task_level': engine.task_level,\n","              'model_state_dict': engine.model.state_dict(),\n","              'optimizer_state_dict': engine.optimizer.state_dict(),\n","              'loss': mvalid_mape,\n","              'train_loss': train_loss_epoch,\n","              'valid_loss': valid_loss_epoch\n","            }, SAVE_PATH)\n","            minl = mvalid_loss\n","\n","    print(\"Average Training Time: {:.4f} secs/epoch\".format(np.mean(train_time)))\n","    print(\"Average Inference Time: {:.4f} secs\".format(np.mean(val_time)))\n","\n","\n","    bestid = np.argmin(his_loss)\n","\n","    writer.close()\n","    print(\"Training finished\")\n","    print(\"The valid loss on best model is\", str(round(his_loss[bestid],4)))\n","\n","    #target_model = args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\"\n","    SAVE_PATH = args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\"\n","    print(\"### loading model is:\",SAVE_PATH ,'###')\n","    #engine.model.load_state_dict(torch.load(args.save + \"exp\" + str(args.expid) + \"_\" + str(runid) +\".pth\"))\n","    checkpoint = torch.load(SAVE_PATH)\n","    engine.model.load_state_dict(checkpoint['model_state_dict'])\n","    engine.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    loss = checkpoint['loss']\n","    print(\"### Loading Model finished ###\")\n","    print(\"### The valid loss on loding model is\", str(round(loss,4)))\n","\n","\n","    #----------------- 此內不能刪掉，不然會crash -----------------------#\n","    #valid data\n","    outputs = []\n","    realy = torch.Tensor(dataloader['y_val']).to(device)\n","    realy = realy.transpose(1,3)[:,0,:,:]\n","    print('#realy', realy.shape)\n","\n","    for iter, (x, y, x_1, x_2) in enumerate(dataloader['val_loader'].get_iterator()):\n","        testx = torch.Tensor(x).to(device)\n","        testx = testx.transpose(1,3)\n","\n","        testx_1 = torch.Tensor(x_1).to(device)\n","        testx_1 = testx_1.transpose(1, 3)\n","        testx_2 = torch.Tensor(x_2).to(device)\n","        testx_2 = testx_2.transpose(1, 3)\n","\n","        with torch.no_grad():\n","            preds = engine.model(testx,testx_1,testx_2)\n","            preds = preds.transpose(1,3)  # 64,1,6,12\n","\n","        outputs.append(preds.squeeze()) # 64,1,6,12 ->squeeze()->64,6,12\n","\n","    yhat = torch.cat(outputs,dim=0)\n","    yhat = yhat[:realy.size(0),...]  # 5240,6,12\n","    print('# cat valid preds', yhat.shape)\n","\n","\n","    #pred = scaler.inverse_transform(yhat)\n","\n","    '''\n","    pred = yhat      # 5240,6,12])\n","    for i in range(args.num_nodes):\n","      pred[:,i,:] = scaler_list[i].inverse_transform(pred[:,i,:])\n","    '''\n","    pred = scaler.inverse_transform(yhat)\n","\n","    vmae, vmape, vrmse,vsmape = metric(pred,realy)\n","    print(\"valid mape\",vmape)\n","    #----------------- 此內不能刪掉，不然會crash -----------------------#\n","\n","\n","    #test data\n","    outputs = []\n","    realy = torch.Tensor(dataloader['y_test']).to(device)\n","    realy = realy.transpose(1, 3)[:, 0, :, :]\n","\n","    for iter, (x, y, x_1, x_2) in enumerate(dataloader['test_loader'].get_iterator()):\n","        testx = torch.Tensor(x).to(device)\n","        testx = testx.transpose(1, 3)\n","\n","        testx_1 = torch.Tensor(x_1).to(device)\n","        testx_1 = testx_1.transpose(1, 3)\n","        testx_2 = torch.Tensor(x_2).to(device)\n","        testx_2 = testx_2.transpose(1, 3)\n","\n","        with torch.no_grad():\n","            preds = engine.model(testx, testx_1, testx_2)\n","            preds = preds.transpose(1, 3)\n","        outputs.append(preds.squeeze())\n","\n","    yhat = torch.cat(outputs, dim=0)\n","    yhat = yhat[:realy.size(0), ...]  #10478, 6, 12\n","    print('# cat test preds', yhat.shape)\n","\n","    mae = []\n","    mape = []\n","    rmse = []\n","    smape = []\n","    for i in range(args.seq_out_len):\n","        #pred = scaler.inverse_transform(yhat[:, :, i])\n","        '''\n","        pred = yhat             # 10478, 6, 12\n","        for j in range(args.num_nodes):\n","          pred[:,j,i] = scaler_list[j].inverse_transform(pred[:,j,i])\n","\n","        real = realy[:, :, i]\n","        real = realy[:, :, i]\n","        metrics = metric(pred[:,:,i], real)\n","        #print(\"#Predict:\",i,\", test maps\", metrics[1])\n","        '''\n","        pred = scaler.inverse_transform(yhat[:, :, i])\n","        #pred = yhat             # 10478, 6, 12\n","        #for j in range(args.num_nodes):\n","        #  pred[:,j,i] = scaler_list[j].inverse_transform(pred[:,j,i])\n","\n","        real = realy[:, :, i]\n","        #real = realy[:, :, i]\n","        #metrics = metric(pred[:,:,i], real)\n","        #print(\"#Predict:\",i,\", test maps\", metrics[1])\n","        metrics = metric(pred, real)\n","\n","        log = 'Evaluate best model on test data for horizon {:d}, Test MAE: {:.4f}, Test MAPE: {:.4f}, Test RMSE: {:.4f}'\n","        print(log.format(i + 1, metrics[0], metrics[1], metrics[2]))\n","        mae.append(metrics[0])\n","        mape.append(metrics[1])\n","        rmse.append(metrics[2])\n","        smape.append(metrics[3])\n","\n","    log = '{:.2f}\t{:.2f}\t{:.4f}\t{:.4f}\t'\n","    print( \"##### exp\" + str(args.expid) + \"_\" + str(runid)+'\t',\n","          log.format(mae[0], rmse[0], smape[0], mape[0]),\n","          log.format(mae[2], rmse[2], smape[2], mape[2]),\n","          log.format(mae[5], rmse[5], smape[5], mape[5]),\n","          log.format(mae[11], rmse[11], smape[11], mape[11]),\n","         )\n","\n","    ### Drawing Loss Diagram ###\n","    fig = plt.figure(figsize=(10, 6), dpi=600)\n","    plt.plot(checkpoint['train_loss'], label=\"train loss\")\n","    plt.plot(checkpoint['valid_loss'], label=\"valid loss\")\n","    plt.legend(loc=\"upper right\")\n","    plt.title('#Loss of Training', fontsize=20)\n","    plt.ylabel(\"MAPE\", fontsize=14)\n","    plt.xlabel(\"Epochs\", fontsize=14)\n","    plt.show()\n","\n","    return vmae, vmape, vrmse,vsmape, mae, mape, rmse,smape\n","\n","if __name__ == \"__main__\":\n","\n","    vmae = []\n","    vmape = []\n","    vrmse = []\n","    vsmape = []\n","    mae = []\n","    mape = []\n","    rmse = []\n","    smape = []\n","    for i in range(args.runs):\n","        vm1, vm2, vm3,vm4, m1, m2, m3, m4 = main(i)\n","        vmae.append(vm1)\n","        vmape.append(vm2)\n","        vrmse.append(vm3)\n","        vsmape.append(vm4)\n","        mae.append(m1)\n","        mape.append(m2)\n","        rmse.append(m3)\n","        smape.append(m4)\n","\n","    mae = np.array(mae)\n","    mape = np.array(mape)\n","    rmse = np.array(rmse)\n","    smape = np.array(smape)\n","\n","    amae = np.mean(mae,0)\n","    amape = np.mean(mape,0)\n","    armse = np.mean(rmse,0)\n","    asmape = np.mean(smape,0)\n","\n","    smae = np.std(mae,0)\n","    s_mape = np.std(mape,0)\n","    srmse = np.std(rmse,0)\n","    s_smape = np.std(smape,0)\n","\n","    print('\\n\\nResults for 10 runs\\n\\n')\n","    #valid data\n","    print('valid\\tMAE\\tRMSE\\tMAPE')\n","    log = 'mean:\\t{:.4f}\\t{:.4f}\\t{:.4f}'\n","    print(log.format(np.mean(vmae),np.mean(vrmse),np.mean(vmape)))\n","    log = 'std:\\t{:.4f}\\t{:.4f}\\t{:.4f}'\n","    print(log.format(np.std(vmae),np.std(vrmse),np.std(vmape)))\n","    print('\\n\\n')\n","    #test data\n","    print('test|horizon\\tMAE-mean\\tRMSE-mean\\tMAPE-mean\\tMAE-std\\tRMSE-std\\tMAPE-std')\n","    for i in [2,5,11]:\n","        log = '{:d}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}'\n","        print(log.format(i+1, amae[i], armse[i], amape[i], smae[i], srmse[i], s_mape[i]))\n"]},{"cell_type":"markdown","source":["# 新增區段"],"metadata":{"id":"r3gZRKtOeDfx"}}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}